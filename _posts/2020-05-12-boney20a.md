---
title: Regularizing Model-Based Planning with Energy-Based Models
abstract: Model-based reinforcement learning could enable sample-efficient learning
  by quickly acquiring rich knowledge about the world and using it to improve behaviour
  without additional data. Learned dynamics models can be directly used for planning
  actions but this has been challenging because of inaccuracies in the learned models.
  In this paper, we focus on planning with learned dynamics models and propose to
  regularize it using energy estimates of state transitions in the environment. We
  visually demonstrate the effectiveness of the proposed method and show that off-policy
  training of an energy estimator can be effectively used to regularize planning with
  pre-trained dynamics models. Further, we demonstrate that the proposed method enables
  sample-efficient learning to achieve competitive performance in challenging continuous
  control tasks such as Half-cheetah and Ant in just a few minutes of experience.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: boney20a
month: 0
tex_title: Regularizing Model-Based Planning with Energy-Based Models
firstpage: 182
lastpage: 191
page: 182-191
order: 182
cycles: false
bibtex_author: Boney, Rinu and Kannala, Juho and Ilin, Alexander
author:
- given: Rinu
  family: Boney
- given: Juho
  family: Kannala
- given: Alexander
  family: Ilin
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/boney20a/boney20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
