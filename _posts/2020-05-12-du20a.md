---
title: Model-Based Planning with Energy-Based Models
abstract: Model-based planning holds great promise for improving both sample efficiency
  and generalization in reinforcement learning (RL). We show that energy-based models
  (EBMs) are a promising class of models to use for model-based planning. EBMs naturally
  support inference of intermediate states given start and goal state distributions.
  We provide an online algorithm to train EBMs while interacting with the environment,
  and show that EBMs allow for significantly better online learning than corresponding
  feed-forward networks. We further show that EBMs support maximum entropy state inference
  and are able to generate diverse state space plans. We show that inference purely
  in state space - without planning actions - allows for better generalization to
  previously unseen obstacles in the environment and prevents the planner from exploiting
  the dynamics model by applying uncharacteristic action sequences. Finally, we show
  that online EBM training naturally leads to intentionally planned state exploration
  which performs significantly better than random exploration.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: du20a
month: 0
tex_title: Model-Based Planning with Energy-Based Models
firstpage: 374
lastpage: 383
page: 374-383
order: 374
cycles: false
bibtex_author: Du, Yilun and Lin, Toru and Mordatch, Igor
author:
- given: Yilun
  family: Du
- given: Toru
  family: Lin
- given: Igor
  family: Mordatch
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/du20a/du20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
