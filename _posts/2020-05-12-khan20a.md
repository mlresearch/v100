---
title: Graph Policy Gradients for Large Scale Robot Control
abstract: In this paper, the problem of learning policies to control a large number
  of homogeneous robots is considered. To this end, we propose a new algorithm we
  call Graph Policy Gradients (GPG) that exploits the underlying graph symmetry among
  the robots. The curse of dimensionality one encounters when working with a large
  number of robots is mitigated by employing a graph convolutional neural (GCN) network
  to parametrize policies for the robots. The GCN reduces the dimensionality of the
  problem by learning filters that aggregate information among robots locally, similar
  to how a convolutional neural network is able to learn local features in an image.
  Through experiments on formation flying, we show that our proposed method is able
  to scale better than existing reinforcement methods that employ fully connected
  networks. More importantly, we show that by using our locally learned filters we
  are able to zero-shot transfer policies trained on just three robots to over hundred
  robots. A video demonstrating our results can be found here.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: khan20a
month: 0
tex_title: Graph Policy Gradients for Large Scale Robot Control
firstpage: 823
lastpage: 834
page: 823-834
order: 823
cycles: false
bibtex_author: Khan, Arbaaz and Tolstaya, Ekaterina and Ribeiro, Alejandro and Kumar,
  Vijay
author:
- given: Arbaaz
  family: Khan
- given: Ekaterina
  family: Tolstaya
- given: Alejandro
  family: Ribeiro
- given: Vijay
  family: Kumar
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/khan20a/khan20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
