---
title: 'S4G: Amodal Single-view Single-Shot SE(3) Grasp Detection in Cluttered Scenes'
abstract: Grasping is among the most fundamental and long-lasting problems in robotics
  study. This paper studies the problem of 6-DoF(degree of freedom) grasping by a
  parallel gripper in a cluttered scene captured using a commodity depth sensor from
  a single viewpoint. We address the problem in a learning-based framework. At the
  high level, we rely on a single-shot grasp proposal network, trained with synthetic
  data and tested in real-world scenarios. Our single-shot neural network architecture
  can predict amodal grasp proposal efficiently and effectively. Our training data
  synthesis pipeline can generate scenes of complex object configuration and leverage
  an innovative gripper contact model to create dense and high-quality grasp annotations.
  Experiments in synthetic and real environments have demonstrated that the proposed
  approach can outperform state-of-the-arts by a large margin.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: qin20a
month: 0
tex_title: 'S4G: Amodal Single-view Single-Shot SE(3) Grasp Detection in Cluttered
  Scenes'
firstpage: 53
lastpage: 65
page: 53-65
order: 53
cycles: false
bibtex_author: Qin, Yuzhe and Chen, Rui and Zhu, Hao and Song, Meng and Xu, Jing and
  Su, Hao
author:
- given: Yuzhe
  family: Qin
- given: Rui
  family: Chen
- given: Hao
  family: Zhu
- given: Meng
  family: Song
- given: Jing
  family: Xu
- given: Hao
  family: Su
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/qin20a/qin20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
