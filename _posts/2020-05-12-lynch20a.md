---
title: Learning Latent Plans from Play
abstract: Acquiring a diverse repertoire of general-purpose skills remains an open
  challenge for robotics. In this work, we propose self-supervising control on top
  of human teleoperated play data as a way to scale up skill learning. Play has two
  properties that make it attractive compared to conventional task demonstrations.
  Play is cheap, as it can be collected in large quantities quickly without task segmenting,
  labeling, or resetting to an initial state. Play is naturally rich, covering ∼4x
  more interaction space than task demonstrations for the same amount of collection
  time. To learn control from play, we introduce Play-LMP, a self-supervised method
  that learns to organize play behaviors in a latent space, then reuse them at test
  time to achieve specific goals. Combining self-supervised control with a diverse
  play dataset shifts the focus of skill learning from a narrow and discrete set of
  tasks to the full continuum of behaviors available in an environment. We find that
  this combination generalizes well empirically—after self-supervising on unlabeled
  play, our method substantially outperforms individual expert-trained policies on
  18 difficult user-specified visual manipulation tasks in a simulated robotic tabletop
  environment. We additionally find that play-supervised models, unlike their expert-trained
  counterparts, are more robust to perturbations and exhibit retrying-till-success
  behaviors. Finally, we find that our agent organizes its latent plan space around
  functional tasks, despite never being trained with task labels. Videos, code and
  data are available at learning-from-play.github.io
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lynch20a
month: 0
tex_title: Learning Latent Plans from Play
firstpage: 1113
lastpage: 1132
page: 1113-1132
order: 1113
cycles: false
bibtex_author: Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and
  Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre
author:
- given: Corey
  family: Lynch
- given: Mohi
  family: Khansari
- given: Ted
  family: Xiao
- given: Vikash
  family: Kumar
- given: Jonathan
  family: Tompson
- given: Sergey
  family: Levine
- given: Pierre
  family: Sermanet
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/lynch20a/lynch20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
