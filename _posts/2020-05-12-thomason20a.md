---
title: Vision-and-Dialog Navigation
abstract: Robots navigating in human environments should use language to ask for assistance
  and be able to understand human responses. To study this challenge, we introduce
  Cooperative Vision-and-Dialog Navigation, a dataset of over 2k embodied, human-human
  dialogs situated in simulated, photorealistic home environments. The Navigator asks
  questions to their partner, the Oracle, who has privileged access to the best next
  steps the Navigator should take according to a shortest path planner. To train agents
  that search an environment for a goal location, we define the Navigation from Dialog
  History task. An agent, given a target object and a dialog history between humans
  cooperating to find that object, must infer navigation actions towards the goal
  in unexplored environments. We establish an initial, multi-modal sequence-to-sequence
  model and demonstrate that looking farther back in the dialog history improves performance.
  Sourcecode and a live interface demo can be found at https://cvdn.dev/
layout: inproceedings
series: Proceedings of Machine Learning Research
id: thomason20a
month: 0
tex_title: Vision-and-Dialog Navigation
firstpage: 394
lastpage: 406
page: 394-406
order: 394
cycles: false
bibtex_author: Thomason, Jesse and Murray, Michael and Cakmak, Maya and Zettlemoyer,
  Luke
author:
- given: Jesse
  family: Thomason
- given: Michael
  family: Murray
- given: Maya
  family: Cakmak
- given: Luke
  family: Zettlemoyer
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/thomason20a/thomason20a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v100/thomason20a/thomason20a-supp.zip
- label: Supplementary video
  link: https://youtu.be/BonlITv_PKw
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
