---
title: 'Masking by Moving: Learning Distraction-Free Radar Odometry from Pose Information'
abstract: This paper presents an end-to-end radar odometry system which delivers robust,
  real-time pose estimates based on a learned embedding space free of sensing artefacts
  and distractor objects. The system deploys a fully differentiable, correlation-based
  radar matching approach. This provides the same level of interpretability as established
  scan-matching methods and allows for a principled derivation of uncertainty estimates.
  The system is trained in a (self-)supervised way using only previously obtained
  pose information as a training signal. Using 280km of urban driving data, we demonstrate
  that our approach outperforms the previous state-of-the-art in radar odometry by
  reducing errors by up 68% whilst running an order of magnitude faster.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: barnes20a
month: 0
tex_title: 'Masking by Moving: Learning Distraction-Free Radar Odometry from Pose
  Information'
firstpage: 303
lastpage: 316
page: 303-316
order: 303
cycles: false
bibtex_author: Barnes, Dan and Weston, Rob and Posner, Ingmar
author:
- given: Dan
  family: Barnes
- given: Rob
  family: Weston
- given: Ingmar
  family: Posner
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/barnes20a/barnes20a.pdf
extras:
- label: Supplementary video
  link: https://youtu.be/eG4Q-j3_6dk
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
