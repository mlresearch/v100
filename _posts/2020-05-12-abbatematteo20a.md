---
title: Learning to Generalize Kinematic Models to Novel Objects
abstract: Robots operating in human environments must be capable of interacting with
  a wide variety of articulated objects such as cabinets, refrigerators, and drawers.
  Existing approaches require human demonstration or minutes of interaction to fit
  kinematic models to each novel object from scratch. We present a framework for estimating
  the kinematic model and configuration of previously unseen articulated objects,
  conditioned upon object type, from as little as a single observation. We train our
  system in simulation with a novel dataset of synthetic articulated objects; at runtime,
  our model can predict the shape and kinematic model of an object from depth sensor
  data. We demonstrate that our approach enables a MOVO robot to view an object with
  its RGB-D sensor, estimate its motion model, and use that estimate to interact with
  the object.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: abbatematteo20a
month: 0
tex_title: Learning to Generalize Kinematic Models to Novel Objects
firstpage: 1289
lastpage: 1299
page: 1289-1299
order: 1289
cycles: false
bibtex_author: Abbatematteo, Ben and Tellex, Stefanie and Konidaris, George
author:
- given: Ben
  family: Abbatematteo
- given: Stefanie
  family: Tellex
- given: George
  family: Konidaris
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/abbatematteo20a/abbatematteo20a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v100/abbatematteo20a/abbatematteo20a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
