---
title: Macro-Action-Based Deep Multi-Agent Reinforcement Learning
abstract: In real-world multi-robot systems, performing high-quality, collaborative
  behaviors requires robots to asynchronously reason about high-level action selection
  at varying time durations. Macro-Action Decentralized Partially Observable Markov
  Decision Processes (MacDec-POMDPs) provide a general framework for asynchronous
  decision making under uncertainty in fully cooperative multi-agent tasks. However,
  multi-agent deep reinforcement learning methods have only been developed for (synchronous)
  primitive-action problems. This paper proposes two Deep Q-Network (DQN) based methods
  for learning decentralized and centralized macro-action-value functions with novel
  macro-action trajectory replay buffers introduced for each case. Evaluations on
  benchmark problems and a larger domain demonstrate the advantage of learning with
  macro-actions over primitive-actions and the scalability of our approaches.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: xiao20a
month: 0
tex_title: Macro-Action-Based Deep Multi-Agent Reinforcement Learning
firstpage: 1146
lastpage: 1161
page: 1146-1161
order: 1146
cycles: false
bibtex_author: Xiao, Yuchen and Hoffman, Joshua and Amato, Christopher
author:
- given: Yuchen
  family: Xiao
- given: Joshua
  family: Hoffman
- given: Christopher
  family: Amato
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/xiao20a/xiao20a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v100/xiao20a/xiao20a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
