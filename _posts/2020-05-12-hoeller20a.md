---
title: Deep Value Model Predictive Control
abstract: In this paper, we introduce an actor-critic algorithm called Deep Value
  Model Predictive Control (DMPC), which combines model-based trajectory optimization
  with value function estimation. The DMPC actor is a Model Predictive Control (MPC)
  optimizer with an objective function defined in terms of a value function estimated
  by the critic. We show that our MPC actor is an importance sampler, which minimizes
  an upper bound of the cross-entropy to the state distribution of the optimal sampling
  policy. In our experiments with a Ballbot system, we show that our algorithm can
  work with sparse and binary reward signals to efficiently solve obstacle avoidance
  and target reaching tasks. Compared to previous work, we show that including the
  value function in the running cost of the trajectory optimizer speeds up the convergence.
  We also discuss the necessary strategies to robustify the algorithm in practice.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hoeller20a
month: 0
tex_title: Deep Value Model Predictive Control
firstpage: 990
lastpage: 1004
page: 990-1004
order: 990
cycles: false
bibtex_author: Hoeller, David and Farshidian, Farbod and Hutter, Marco
author:
- given: David
  family: Hoeller
- given: Farbod
  family: Farshidian
- given: Marco
  family: Hutter
date: 2020-05-12
address: 
publisher: PMLR
container-title: Proceedings of the Conference on Robot Learning
volume: '100'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 5
  - 12
pdf: http://proceedings.mlr.press/v100/hoeller20a/hoeller20a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v100/hoeller20a/hoeller20a-supp.zip
- label: Supplementary video
  link: https://youtu.be/9p4qHBUZDMA
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
